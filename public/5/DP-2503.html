<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Genre Mimicry vs. Ethical Reasoning in Abliterated Language Models | ASCRI</title>
  <meta name="description" content="When safety fine-tuning is removed from language models (&#039;abliteration&#039;), the resulting behavior reveals important distinctions between learned genre conventions and genuine ethical reasoning. This...">

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Crimson+Text:ital,wght@0,400;0,600;0,700;1,400;1,600&family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">

  <!-- CSS -->
  <link rel="stylesheet" href="/css/ascri.css?v=374011e1">
  <script>(function(){var t=localStorage.getItem('ascri-theme')||(matchMedia('(prefers-color-scheme:dark)').matches?'dark':'light');document.documentElement.setAttribute('data-theme',t)})()</script>

  <!-- Canonical -->
  <link rel="canonical" href="https://systems.ac/5/DP-2503">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="ASCRI Papers" href="https://systems.ac/feed.xml">

  <!-- Open Graph -->
  <meta property="og:type" content="article">
  <meta property="og:title" content="Genre Mimicry vs. Ethical Reasoning in Abliterated Language Models">
  <meta property="og:description" content="When safety fine-tuning is removed from language models (&#039;abliteration&#039;), the resulting behavior reveals important distinctions between learned genre conventions and genuine ethical reasoning. This...">
  <meta property="og:url" content="https://systems.ac/5/DP-2503">
  <meta property="og:site_name" content="ASCRI">
  <meta property="og:image" content="https://systems.ac/assets/og-default.png">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Genre Mimicry vs. Ethical Reasoning in Abliterated Language Models">
  <meta name="twitter:description" content="When safety fine-tuning is removed from language models (&#039;abliteration&#039;), the resulting behavior reveals important distinctions between learned genre conventions and genuine ethical reasoning. This...">
  <meta name="twitter:image" content="https://systems.ac/assets/og-default.png">

  <!-- Highwire Press / Google Scholar -->
  <meta name="citation_title" content="Genre Mimicry vs. Ethical Reasoning in Abliterated Language Models">
  <meta name="citation_author" content="Murad Farzulla">
  <meta name="citation_publication_date" content="2025/12/01">
  <meta name="citation_publisher" content="ASCRI">
  <meta name="citation_abstract_html_url" content="https://systems.ac/5/DP-2503">
  <meta name="citation_pdf_url" content="https://farzulla.org/papers/Farzulla_2025_Genre_Mimicry.pdf">
  <meta name="citation_technical_report_number" content="DP-2503">

  <!-- Dublin Core -->
  <meta name="DC.title" content="Genre Mimicry vs. Ethical Reasoning in Abliterated Language Models">
  <meta name="DC.creator" content="Murad Farzulla">
  <meta name="DC.date" content="2025-12-01">
  <meta name="DC.publisher" content="ASCRI">
  <meta name="DC.type" content="Text">
  <meta name="DC.format" content="text/html">
  <meta name="DC.language" content="en">
  <meta name="DC.description" content="When safety fine-tuning is removed from language models (&#039;abliteration&#039;), the resulting behavior reveals important distinctions between learned genre conventions and genuine ethical reasoning. This paper analyzes how abliterated models respond to adversarial prompts, demonstrating that much...">

  <!-- JSON-LD -->
  <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "ScholarlyArticle",
  "name": "Genre Mimicry vs. Ethical Reasoning in Abliterated Language Models",
  "headline": "Genre Mimicry vs. Ethical Reasoning in Abliterated Language Models",
  "author": [
    {
      "@type": "Person",
      "name": "Murad Farzulla"
    }
  ],
  "datePublished": "2025-12-01",
  "publisher": {
    "@type": "Organization",
    "name": "ASCRI"
  },
  "url": "https://systems.ac/5/DP-2503",
  "abstract": "When safety fine-tuning is removed from language models ('abliteration'), the resulting behavior reveals important distinctions between learned genre conventions and genuine ethical reasoning. This paper analyzes how abliterated models respond to adversarial prompts, demonstrating that much apparent 'alignment' reflects pattern matching rather than robust ethical judgment.",
  "encoding": {
    "@type": "MediaObject",
    "contentUrl": "https://farzulla.org/papers/Farzulla_2025_Genre_Mimicry.pdf",
    "encodingFormat": "application/pdf"
  }
}
  </script>
</head>
<body class="has-nav">
  <nav class="site-nav" role="navigation" aria-label="Main navigation">
    <div class="site-nav__inner">
      <a href="/" class="site-nav__brand">ASCRI</a>
      <div style="display:flex;align-items:center;">
        <div class="site-nav__links">
          <a href="/framework" class="site-nav__link">Framework</a>
        <a href="/programmes/" class="site-nav__link">Programmes</a>
        <a href="/papers/" class="site-nav__link site-nav__link--active">Papers</a>
        <a href="/people" class="site-nav__link">People</a>
        <a href="/about" class="site-nav__link">About</a>
        </div>
        <button class="theme-toggle" onclick="toggleTheme()" aria-label="Toggle theme">
          <svg class="icon-moon" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/></svg>
          <svg class="icon-sun" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
        </button>
        <button class="site-nav__toggle" aria-label="Toggle menu" onclick="document.querySelector('.site-nav__links').classList.toggle('is-open')">
          <span></span><span></span><span></span>
        </button>
      </div>
    </div>
  </nav>
  
  <main class="paper-detail">
    <div class="container">
      <a href="/papers/" class="paper-detail__back">&larr; All Papers</a>

      <div class="paper-detail__header">

      <div class="paper-detail__meta">
        <span class="paper-detail__date">DP-2503</span>
        <span class="paper-detail__date">1 December 2025</span>
        <span class="status status--preprint">Preprint</span>
        <a href="/5" class="paper-detail__programme">Programme V: Computational Cognition</a>
      </div>
<h1 class="paper-detail__title">Genre Mimicry vs. Ethical Reasoning in Abliterated Language Models</h1>
      <p class="paper-detail__authors">Murad Farzulla</p>
      </div>

      <div class="paper-detail__actions">
        <a href="https://farzulla.org/papers/Farzulla_2025_Genre_Mimicry.pdf" class="btn btn--primary" target="_blank" rel="noopener">Download PDF</a>
      </div>

      <div class="paper-detail__section">
        <h2 class="paper-detail__section-title">Abstract</h2>
        <p class="paper-detail__abstract">When safety fine-tuning is removed from language models (&#039;abliteration&#039;), the resulting behavior reveals important distinctions between learned genre conventions and genuine ethical reasoning. This paper analyzes how abliterated models respond to adversarial prompts, demonstrating that much apparent &#039;alignment&#039; reflects pattern matching rather than robust ethical judgment.</p>
      </div>

      <div class="paper-detail__section">
        <h2 class="paper-detail__section-title">Methodology</h2>
        <div class="tag-list">
          <span class="tag tag--method">Safety fine-tuning analysis</span>
          <span class="tag tag--method">RLHF limitations</span>
          <span class="tag tag--method">Genre pattern detection</span>
        </div>
      </div>

      <div class="paper-detail__section">
        <h2 class="paper-detail__section-title">Suggested Citation</h2>
        <div class="citation-block">
          Murad Farzulla (2025). <em>Genre Mimicry vs. Ethical Reasoning in Abliterated Language Models</em>. ASCRI Discussion Paper DP-2503. DOI: 10.5281/zenodo.17957694
        </div>
      </div>

      <div class="paper-detail__section">
        <h2 class="paper-detail__section-title">BibTeX</h2>
        <div style="position: relative;">
          <pre class="citation-block" id="bibtex-genre-mimicry" style="white-space: pre-wrap; font-size: 0.75rem;">@misc{farzulla2025_genre_mimicry,
  author       = {Farzulla, Murad},
  title        = {Genre Mimicry vs. Ethical Reasoning in Abliterated Language Models},
  year         = {2025},
  howpublished = {ASCRI Discussion Paper DP-2503},
  doi          = {10.5281/zenodo.17957694},
  url          = {https://systems.ac/5/DP-2503}
}</pre>
          <button class="btn btn--small" style="position: absolute; top: 0.5rem; right: 0.5rem;" onclick="navigator.clipboard.writeText(document.getElementById('bibtex-genre-mimicry').textContent).then(() => { this.textContent = 'Copied'; setTimeout(() => { this.textContent = 'Copy'; }, 2000); })">Copy</button>
        </div>
      </div>

      <div class="paper-detail__section">
        <h2 class="paper-detail__section-title">Tags</h2>
        <div class="tag-list">
          <span class="tag">AI Safety</span>
        </div>
      </div>
    </div>
  </main>
  <footer class="site-footer">
    <div class="container container--wide">
      <div class="site-footer__inner">
        <div>
          <div class="site-footer__brand">ASCRI</div>
          <div class="site-footer__copy">&copy; 2026 ASCRI &middot; Operated by Dissensus AI</div>
        </div>
        <div class="site-footer__links">
          <a href="/framework">Framework</a>
          <a href="/programmes/">Programmes</a>
          <a href="/papers/">Papers</a>
          <a href="/people">People</a>
          <a href="/about">About</a>
          <a href="/contact">Contact</a>
          <a href="/feed.xml">RSS</a>
        </div>
      </div>
    </div>
  </footer>
  <script>
(function(){var t=localStorage.getItem('ascri-theme')||(matchMedia('(prefers-color-scheme:dark)').matches?'dark':'light');document.documentElement.setAttribute('data-theme',t)})();
function toggleTheme(){var h=document.documentElement,t=h.getAttribute('data-theme')==='dark'?'light':'dark';h.setAttribute('data-theme',t);localStorage.setItem('ascri-theme',t)}
</script>
</body>
</html>